{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d83207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/Users/shubh/Desktop/Aww/MetaData_Cleaned.csv' created with metadata for all.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ks/khrkjrdn6ms4yvtd6kj2hn2m0000gn/T/ipykernel_599/195703345.py:17: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  @validator('amazon_storage_class')\n",
      "/var/folders/ks/khrkjrdn6ms4yvtd6kj2hn2m0000gn/T/ipykernel_599/195703345.py:24: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  @validator('file_size_kb')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for the script\n",
    "from pydantic import BaseModel, HttpUrl, validator  # Pydantic for data modeling and validation\n",
    "from datetime import datetime  # datetime for handling date and time\n",
    "import csv  # csv for CSV file operations\n",
    "\n",
    "# Define a Pydantic model for the metadata of PDF files\n",
    "class MetaDataPDFClass(BaseModel):\n",
    "    level: str  # The level of the PDF file (e.g., I, II, III)\n",
    "    file_size_kb: float  # The size of the PDF file in kilobytes\n",
    "    amazon_storage_class: str  # The Amazon S3 storage class of the PDF file\n",
    "    s3_text_link: HttpUrl  # The HTTP URL to the PDF file stored in Amazon S3\n",
    "    file_path: str  # The file path of the PDF file\n",
    "    content_type: str = \"txt\"  # Default content type set to text\n",
    "    date_updated: datetime  # The date when the PDF file was last updated\n",
    "\n",
    "    # Define a validator to ensure the Amazon storage class is either 'Standard' or 'Glacier'\n",
    "    @validator('amazon_storage_class')\n",
    "    def storage_class_must_be_standard_or_glacier(cls, v):\n",
    "        if v not in [\"Standard\", \"Glacier\"]:\n",
    "            raise ValueError('Amazon_storage_class must be \"Standard\" or \"Glacier\"')\n",
    "        return v\n",
    "\n",
    "    # Define a validator to ensure the file size is a positive number\n",
    "    @validator('file_size_kb')\n",
    "    def file_size_must_be_positive(cls, v):\n",
    "        if v <= 0:\n",
    "            raise ValueError('file_size_kb must be a positive number')\n",
    "        return v\n",
    "\n",
    "# Metadata for all six PDF files\n",
    "pdf_data = [\n",
    "    {\"level\": \"I\", \"file_size_kb\": 35.8, \"amazon_storage_class\": \"Standard\", \"s3_text_link\": \"https://cfa-assignment2.s3.us-east-2.amazonaws.com/data/Grobid_RR_2024_LevelI_combined.txt\", \"file_path\": \"data/Grobid_RR_2024_LevelI_combined.txt\", \"date_updated\": \"2024-02-27\"},\n",
    "    {\"level\": \"II\", \"file_size_kb\": 37.5, \"amazon_storage_class\": \"Standard\", \"s3_text_link\": \"https://cfa-assignment2.s3.us-east-2.amazonaws.com/data/Grobid_RR_2024_LevelII_combined.txt\", \"file_path\": \"data/Grobid_RR_2024_LevelII_combined.txt\", \"date_updated\": \"2024-02-27\"},\n",
    "    {\"level\": \"III\", \"file_size_kb\": 21.1, \"amazon_storage_class\": \"Standard\", \"s3_text_link\": \"https://cfa-assignment2.s3.us-east-2.amazonaws.com/data/Grobid_RR_2024_LevelIII_combined.txt\", \"file_path\": \"data/Grobid_RR_2024_LevelIII_combined.txt\", \"date_updated\": \"2024-02-27\"},\n",
    "    {\"level\": \"I\", \"file_size_kb\": 45, \"amazon_storage_class\": \"Standard\", \"s3_text_link\": \"https://cfa-assignment2.s3.us-east-2.amazonaws.com/data/PyPDF_2024_l1_combined.txt\", \"file_path\": \"data/PyPDF_2024_l1_combined.txt\", \"date_updated\": \"2024-02-27\"},\n",
    "    {\"level\": \"II\", \"file_size_kb\": 46, \"amazon_storage_class\": \"Standard\", \"s3_text_link\": \"https://cfa-assignment2.s3.us-east-2.amazonaws.com/data/PyPDF_2024_l2_combined.txt\", \"file_path\": \"data/PyPDF_2024_l2_combined.txt\", \"date_updated\": \"2024-02-27\"},\n",
    "    {\"level\": \"III\", \"file_size_kb\": 30, \"amazon_storage_class\": \"Standard\", \"s3_text_link\": \"https://cfa-assignment2.s3.us-east-2.amazonaws.com/data/PyPDF_2024_l3_combined.txt\", \"file_path\": \"data/PyPDF_2024_l3_combined.txt\", \"date_updated\": \"2024-02-27\"}\n",
    "]\n",
    "\n",
    "# Create instances of MetaDataPDFClass for each item in `pdf_data`\n",
    "pdf_instances = [MetaDataPDFClass(**data) for data in pdf_data]\n",
    "\n",
    "# Specify the output CSV file name\n",
    "csv_file = \"/Users/shubh/Desktop/Aww/MetaData_Cleaned.csv\"\n",
    "\n",
    "# Open the CSV file and write the metadata of each PDF instance\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header row to the CSV file\n",
    "    writer.writerow(['Level', 'File Size (KB)', 'Amazon Storage Class', 'S3 Text Link', 'File Path', 'Content Type', 'Date Updated'])\n",
    "    # Iterate through each PDF instance and write its metadata to the CSV\n",
    "    for instance in pdf_instances:\n",
    "        writer.writerow([\n",
    "            instance.level, \n",
    "            instance.file_size_kb, \n",
    "            instance.amazon_storage_class, \n",
    "            instance.s3_text_link, \n",
    "            instance.file_path, \n",
    "            instance.content_type, \n",
    "            instance.date_updated.strftime('%Y-%m-%d')  # Format the date_updated field\n",
    "        ])\n",
    "\n",
    "# Print a confirmation message after successfully creating the CSV file\n",
    "print(f\"CSV file '{csv_file}' created with metadata for all.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5359884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
